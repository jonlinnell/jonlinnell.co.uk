---
title: Can AI Code? Part 1
date: 2023-04-05T10:00:00.000Z
keywords: ai,js
heroimage: /blog/images/testimage.png
---

On the subject of generative AI, I bounce back and forth between gleeful childish optimism, and something approaching apocalyptic terror.

I may well write a full egotistical opinion piece on that another time, but for now I'll summarise by saying that the practical applications of neural networks and LLMs in fields like science and medicine will quite likely be a revolutionary force for good in the medium and long term. But, as with almost all technology, there are countless and unforeseeable negative applications too. Although I don't think the AIs are going to turn sentient and decide to exterminate us, I'm more concerned that LLMs will continue to be exploited by dark political actors and authoritarian nation states for anti-democratic purposes. There's a real risk that convincing populist misinformation can be produced so cheaply and so prodigiously that it eventually reduces human society to something subservient and pitiful, or drive us all into solipsist madness. Though it's unlikely to be _quite_ that bad, the prospect of machines that can write natural language in a convincingly coherent fashion is staggering, and until I actually started using an LLM, I struggled to keep the fear in check.

Society's presumably impending collapse aside (this is sarcasm, if you're in an AI anxiety phase), the other worry about advanced LLMs and generative AI is that it will replace software engineers. As all software engineers have had to do in the last six months, I've considered the possibility that an AI could come along and automate me out of a job. For a while I was almost convinced; the seemingly weekly quantum leaps in computing capability made this seem inevitable. The hype fire has burned down somewhat, and I don't think that's likely any more. I no more think AI will make software engineers redundant than I think DAWs will make musicians obsolete, or a really fancy automated hammer will make builders a thing of the past; you still need someone who understands music, who knows what a house needs to be and do for the tools to have value.

As a seemingly increasing number of engineers seem to have done already, I'm arriving at the conclusion that generative AI is an assistive tool, something that can help us build the things we build by at least partly automating some source code writing. I've experimented with GPT-3 for a little while, and far from being scared into assuming I'll be out of a job in the next few years, I've actually been relieved that it is both more useful than I hoped, and less useful than I feared. (Side-note: I'm aware that GPT-3.5 and 4 are both more powerful than GPT-3, but that shouldn't matter much for the cases I'm investigating. From what I've read about GPT-4, I'm ready to raise my eyebrows by no more than a couple of millimetres.)

Modern software engineering, for the majority of us, is about far more than just writing source code. There's a tremendous amount of reasoning and planning; architecture and building, which require cognition and reasoning. At a basic level, these are things that generative AIs are simply can't do, no matter how hard the blow-hards blow.

With that in mind, I wanted to know how useful an LLM would be as a coding tool, something to generate source code for me. I asked it to do something that I've had to implement a couple of times in my career: given an input array, split that array into several smaller arrays of a given size. Let's see how the robot got on with that.

> Write a function in JavaScript to divide an array of items into smaller arrays of variable length.

```js
function chunkArray(arr, size) {
  const chunkedArr = [];
  for (let i = 0; i < arr.length; i += size) {
    chunkedArr.push(arr.slice(i, i + size));
  }
  return chunkedArr;
}
```

This is what I'd expect to see on Stack Overflow; a simple `for` loop that does the job. The formatting is a bit weird and clunky, and it's a little hard to grok. But, importantly, it _does_ work. Let's see if we can get it to generate something similar using slightly different syntax:

> Write a function in JavaScript to divide an array of items into smaller arrays of variable length. You must use the Array.reduce method, and must not use a for loop.

```js
function chunkArrayReduce(arr, size) {
  return arr.reduce((acc, el, i) => {
    const div = Math.floor(i / size);
    if (!acc[div]) {
      acc[div] = [];
    }
    acc[div].push(el);
    return acc;
  }, []);
}
```

I've implemented this function in exactly the same way for years, so this is a good result. I find it interesting how it changed the name of the function and the names of the variables, and how it added a guard against undefined chunks without being told that was a risk. I mostly use TypeScript these days, so let's ask it to add in some types.

> Refactor the chunkArrayReduce function in TypeScript. The array must use a generic type.

```typescript
function chunkArrayReduce<T>(arr: T[], size: number): T[][] {
  return arr.reduce((acc, el, i) => {
    const div = Math.floor(i / size);
    if (!acc[div]) {
      acc[div] = [];
    }
    acc[div].push(el);
    return acc;
  }, []);
}
```

The fact that it can correctly apply generic types with minimal prompting is quite impressive. This is already a useful tool; it would have taken me a couple of minutes to write that, and there's a good chance I'd make a reasoning error in there or, worse, reach for a third-party library like Lodash.

It's written a bit of code for me, but crucially, it has not made me obsolete as developer. This function on its own is useless, similarly, some coordinating entity needs to know that this function is required at all. There are logical leaps to be made regarding the necessity of a piece of code, and the subsequent utilisation of that code. Generative AI can do neither.

That's a basic bit of code I'd expect any junior developer a little way into a bootcamp to be able to do, to some degree of quality. Let's try something more difficult. Timezones are a pain in the neck, localising times between timezones can be an absolute nightmare, especially if you have to do multiple hops, for whatever reason. Let's ask the LLM if it can write me a function to get the number of minutes offset from UTC for a given city.

> Write a function in JavaScript that returns the number of minutes offset from UTC for a given city.

```js
function getTimezoneOffset(city) {
  let offset = Intl.DateTimeFormat().resolvedOptions().timeZone;
  if (city) {
    offset = Intl.DateTimeFormat(undefined, { timeZone: city }).resolvedOptions().timeZone;
  }

  const tz = new Date().getTimezoneOffset();
  return tz + Intl.DateTimeFormat().resolvedOptions().timeZone.offset;
}
```

This took me by surprise at first; it looks pretty convincing, it's using the datetime methods available to us through `Intl` and everything, and I can imagine an engineer just whacking this into their work and not giving it any thought. , until it inevitably doesn't work.

The `offset` property is bizarrely set to the name of a timezone (the IANA name, like 'Europe/London', not the name of a city; if we provide a city name, it will not be able to resolve the TZ name). It is then disregarded and never referenced again. The LLM then tries to use a non-existent property in a calculation with the current timezone offset; `timeZone` is a string, so `offset` will always be undefined. The output of this function will always be `NaN`. The AI failed us there; it's not even remotely salvageable.

Maybe I'm being unfair - I deliberately asked it to only take the name of a city to see how it would handle the ambiguity, but that was clearly a step too far. Let's try again.

> Write a function in JavaScript that takes the name of a timezone as its argument, and returns the number of minutes offset from UTC for that timezone.

```js
function getUTCOffset(timezone) {
  let offset = 0;
  if (timezone) {
    const tz = new Date().getTimezoneOffset();
    const timezoneOffset = Intl.DateTimeFormat(undefined, { timeZone: timezone }).resolvedOptions()
      .timeZone.offset;
    offset = tz + timezoneOffset;
  }
  return offset;
}
```

I really don't know where it's getting this from; this is simply incorrect. The result will always be 0 at best, and `NaN` at worst.

Let's try giving it an example.

> Write a function in JavaScript that takes the name of a timezone as its argument, and returns the number of minutes that timezone is offset from UTC. The function should be compatible with Node.js 16 and up.

> For example:
> Input: 'Europe/London'
> Output: -60
> Input 'America/New_York'
> Output: 300

This produced exactly the same result as above, which I'll assume is the end of this particular journey; GPT-3 simply can't do it. There are plenty of correct-ish solutions, including some particularly hacky ones involving Regex-ing the offset out of a localised date using Intl, which is probably what I'd try to do at first!

How about simply localising a given UTC time?

> Write a function in JavaScript that takes the name of a timezone and an ISO8601 string date in UTC as its arguments, and localises the date to the given timezone.

```ts
function localiseDate(timezone, dateString) {
  let date = new Date(dateString);
  let offset = getTimezoneOffset(timezone);
  date.setMinutes(date.getMinutes() + offset);
  return date;
}
```

It tried to use its own non-functional function. Mutating the time alone is also not ideal for many reasons.

Given this is the kind of task I would expect any professional engineer to be able to do without much thought, I think my job is safe enough for the time being.

I'm hoping to make this a series. There are many subjects I want to explore, such as getting an LLM to create an integration for third party data sources, write test suites, write larger and more impactful implementations and so on. As a software engineer, I remain unconvinced that AI will replace our jobs, but will instead eventually come to augment our toolkit and, in a best-case scenario, lead to less time wasted on fiddly little functions that can often by the lynchpin of a business-critical application. I particularly want to see if GPT-4 is any better at some of these challenges.
